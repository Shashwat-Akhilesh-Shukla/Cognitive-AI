version: '3.8'

# Enable BuildKit for faster builds with cache mounts
x-buildkit-env: &buildkit-env
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: ai-therapist-postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-ai_therapist}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-changeme}
      - POSTGRES_DB=${POSTGRES_DB:-ai_therapist}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - ai-therapist-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-ai_therapist}" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: ai-therapist-redis
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - ai-therapist-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend Service (FastAPI)
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: ai-therapist-backend
    ports:
      - "8000:8000" # Backend API
    environment:
      # Database Configuration
      - DATABASE_URL=postgresql://${POSTGRES_USER:-ai_therapist}:${POSTGRES_PASSWORD:-changeme}@postgres:5432/${POSTGRES_DB:-ai_therapist}
      - REDIS_URL=redis://redis:6379/0

      # API Keys
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_ENVIRONMENT=${PINECONE_ENVIRONMENT:-us-west4-gcp-free}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - JINA_API_KEY=${JINA_API_KEY}

      # Application Settings
      - STM_TTL=${STM_TTL:-3600}
      - FRONTEND_URL=http://frontend:3000
      - NODE_ENV=production
      - PYTHONUNBUFFERED=1

      # Voice & GPU Settings
      - VOICE_ENABLED=true
      - MODEL_CACHE_DIR=/app/models
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Optional: Force specific device (cpu/cuda)
      # - FORCE_DEVICE=cpu

      # Optional: Custom model configurations
      # - WHISPER_MODEL=openai/whisper-small  # Use smaller model for lower latency
      # - COQUI_MODEL=tts_models/en/ljspeech/tacotron2-DDC

    volumes:
      # Persist model cache (prevents re-downloading on restart)
      - ai-therapist-models:/app/models

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

    networks:
      - ai-therapist-network

    restart: unless-stopped

    # GPU Configuration (optional, gracefully ignored if GPU not available)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all # Use all available GPUs
              capabilities: [ gpu ]

    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s # Increased for model loading time

  # Frontend Service (Next.js)
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: ai-therapist-frontend
    ports:
      - "3000:3000" # Frontend
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      # Internal backend URL for server-side requests
      - BACKEND_URL=http://backend:8000

    depends_on:
      backend:
        condition: service_healthy

    networks:
      - ai-therapist-network

    restart: unless-stopped

    healthcheck:
      test: [ "CMD", "node", "-e", "require('http').get('http://localhost:3000', (r) => {if (r.statusCode !== 200) throw new Error(r.statusCode)})" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

networks:
  ai-therapist-network:
    driver: bridge

volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  ai-therapist-models:
    driver: local
